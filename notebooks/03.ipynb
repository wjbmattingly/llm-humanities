{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/tapi-logo-small.png\" />\n",
    "\n",
    "This notebook free for educational reuse under [Creative Commons CC BY License](https://creativecommons.org/licenses/by/4.0/).\n",
    "\n",
    "Created by [William Mattingly](https://www.wjbmattingly.com) for the 2025 Text Analysis Pedagogy Institute, with support from [Constellate](https://constellate.org).\n",
    "<br />\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving the Output of LLMs for Analaysis\n",
    "\n",
    "In this notebook we will use what we have learned to generate better outputs from LLMs. In this notebook, you will have the following:\n",
    "\n",
    "\n",
    "1) Understanding of how to include other classes for the model and why these can improve outputs.\n",
    "2) How to perform OCR Correction with an LLM and, more importantly, some of the problems with this approach\n",
    "3) How to leverage NER for downstream tasks, such as the creation of knowledge graphs\n",
    "4) How to use the skills you have learned this week to tackle a real-world problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (1.73.0)\n",
      "Requirement already satisfied: pydantic in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (2.11.3)\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (3.2.0)\n",
      "Requirement already satisfied: spacy in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (3.8.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from pydantic) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from pydantic) (0.4.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from datasets) (2.1.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from datasets) (3.11.11)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from datasets) (0.27.1)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from spacy) (0.15.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from spacy) (3.1.5)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from spacy) (75.1.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Requirement already satisfied: wrapt in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/python312/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install openai pydantic datasets spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Dataset\n",
    "\n",
    "First let's go ahead and import the dataset we will be using throughout this notebook, the American Stories dataset. Here, we are using a very small sample of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/python312/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['article_id', 'newspaper_name', 'edition', 'date', 'page', 'headline', 'byline', 'article'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"wjbmattingly/american-stories-sample-tap\", split=\"train\")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like before, we will be working with this article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "British. Surrender to Nozs Dotes\n",
      "\n",
      " Back to Three Post-ANor Decisions; Hitler Saw They Would Not Fight After They Let Itoly. Toke Ethiopio;\n",
      "\n",
      " After France Let Them Toke Rhnelond;; M w And When Franco Was Not Checked\n",
      "\n",
      " WASHINGTON, September g. - Here are two. tl1vb-naN sketches of history which should be kept in Av1\n"
     ]
    }
   ],
   "source": [
    "print(dataset[2]['article'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up OpenAI API\n",
    "\n",
    "In order to follow along with this notebook, remember to setup your OpenAI credentials and use your API Key. We will first import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's connect to the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    # api_key=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding other Options for the Model to Consider\n",
    "\n",
    "In the previous notebook, we saw the benefits of few-shot learning with LLMs and well-crafted prompts. Here, I'd like to demonstrate another approach. We will be using additional classes, namely Person. The idea behind providing the model additional classes is that it can have other options to classify certain entities that may be mislabeled. This can sometimes improve the NER output of a model. To begin, we will create two classes: Location and Person. Note that we are using a slightly different NER prompt than we did in the previous notebook.\n",
    "\n",
    "Finally, we will have a third class: Entities. This will be a list of the entities in the text which will map to both locations and places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('locations', [Location(text='British'), Location(text='Nozs Dotes'), Location(text='ANor'), Location(text='Itoly'), Location(text='Ethiopio'), Location(text='France'), Location(text='Rhnelond'), Location(text='WASHINGTON')])\n",
      "('people', [Person(text='Hitler'), Person(text='Franco')])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ner_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant that identifies entities in a text.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Find entities in this text:: {dataset[2]['article']}\"\n",
    "    }\n",
    "]\n",
    "\n",
    "class Location(BaseModel):\n",
    "    text: str\n",
    "\n",
    "class Person(BaseModel):\n",
    "    text: str\n",
    "\n",
    "class Entities(BaseModel):\n",
    "    locations: list[Location]\n",
    "    people: list[Person]\n",
    "\n",
    "response = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=ner_messages,\n",
    "    response_format=Entities\n",
    ")\n",
    "\n",
    "for response in response.choices[0].message.parsed:\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run this cell multiple times, you will notice that we (as expected) have rather inconsistent output. One of the main things I have noticed is that this model continues to assign things like `British` to Person and Location unpredictably."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **EXERCISE 1** (10 minutes)\n",
    "Your exercise is to solve the above noted problem. Based on what you've learned so far, come up with a solution that will prevent this from happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"locations\":[{\"text\":\"Britain\"},{\"text\":\"Nozs Dotes\"},{\"text\":\"Hitler\"},{\"text\":\"Itoly\"},{\"text\":\"Ethiopio\"},{\"text\":\"France\"},{\"text\":\"Rhnelond\"},{\"text\":\"Franco\"},{\"text\":\"WASHINGTON\"}],\"people\":[{\"text\":\"Hitler\"},{\"text\":\"Franco\"}]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "imrpoved = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant that identifies entities in a text.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Find entities in this text: {dataset[2]['article']}\"\n",
    "    }\n",
    "]\n",
    "\n",
    "class Location(BaseModel):\n",
    "    text: str\n",
    "\n",
    "class Person(BaseModel):\n",
    "    text: str\n",
    "\n",
    "class Entities(BaseModel):\n",
    "    locations: list[Location]\n",
    "    people: list[Person]\n",
    "\n",
    "response = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=imrpoved,\n",
    "    response_format=Entities\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance of OCR Correction?\n",
    "\n",
    "One of the main reasons the model struggles with the text in question is that it being given a poorly-OCRed text. OCR correction is an area of active research, especially with SMLs, or small language models. LLMs and SMLs can perform OCR correction, but one of the main issues is that these are generative models, meaning they can hallucinate and do so in entirely unpredictable ways. They can sometimes convert bad OCR of early-modern Italian into proper modern Italy. It's important to understand that LLMs, if used for OCR correction, should be manually validated.\n",
    "\n",
    "For the purposes of today, though, let's go ahead and use an LLM to do this. To do this, we will craft a slightly different prompt and Pydantic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"text\":\"British Surrender to Nazis Dotes\\n\\nBack to Three Post-War Decisions: Hitler Saw They Would Not Fight After They Let Italy Take Ethiopia;\\n\\nAfter France Let Them Take Rhineland; And When Franco Was Not Checked\\n\\nWASHINGTON, September 9. - Here are two thumbnail sketches of history which should be kept in view.\"}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ocr_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant that cleans OCR errors in a text.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Clean OCR errors in this text: {dataset[2]['article']}\"\n",
    "    }\n",
    "]\n",
    "\n",
    "class CorrectedText(BaseModel):\n",
    "    text: str\n",
    "\n",
    "response = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=ocr_messages,\n",
    "    response_format=CorrectedText\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! Let's now grab this as structured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='British Surrender to Nazis Dotes\\n\\nBack to Three Post-War Decisions: Hitler Saw They Would Not Fight After They Let Italy Take Ethiopia;\\n\\nAfter France Let Them Take Rhineland; And When Franco Was Not Checked\\n\\nWASHINGTON, September 9. - Here are two thumbnail sketches of history which should be kept in view.'\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's make it into a an object we can call later in our script. We will call this `corrected_text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "British Surrender to Nazis Dotes\n",
      "\n",
      "Back to Three Post-War Decisions: Hitler Saw They Would Not Fight After They Let Italy Take Ethiopia;\n",
      "\n",
      "After France Let Them Take Rhineland; And When Franco Was Not Checked\n",
      "\n",
      "WASHINGTON, September 9. - Here are two thumbnail sketches of history which should be kept in view.\n"
     ]
    }
   ],
   "source": [
    "corrected_text = response.choices[0].message.parsed.text\n",
    "print(corrected_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare it to our original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "British. Surrender to Nozs Dotes\n",
      "\n",
      " Back to Three Post-ANor Decisions; Hitler Saw They Would Not Fight After They Let Itoly. Toke Ethiopio;\n",
      "\n",
      " After France Let Them Toke Rhnelond;; M w And When Franco Was Not Checked\n",
      "\n",
      " WASHINGTON, September g. - Here are two. tl1vb-naN sketches of history which should be kept in Av1\n"
     ]
    }
   ],
   "source": [
    "print(dataset[2]['article'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<h2>Original vs Corrected Text</h2>\n",
       "<table style=\"width:100%; border-collapse: collapse;\">\n",
       "    <tr>\n",
       "        <th style=\"border: 1px solid black; padding: 8px; text-align: left; background-color: #f2f2f2;\">Original Text</th>\n",
       "        <th style=\"border: 1px solid black; padding: 8px; text-align: left; background-color: #f2f2f2;\">Corrected Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"border: 1px solid black; padding: 8px; vertical-align: top; white-space: pre-wrap;\">British. Surrender to Nozs Dotes\n",
       "\n",
       " Back to Three Post-ANor Decisions; Hitler Saw They Would Not Fight After They Let Itoly. Toke Ethiopio;\n",
       "\n",
       " After France Let Them Toke Rhnelond;; M w And When Franco Was Not Checked\n",
       "\n",
       " WASHINGTON, September g. - Here are two. tl1vb-naN sketches of history which should be kept in Av1</td>\n",
       "        <td style=\"border: 1px solid black; padding: 8px; vertical-align: top; white-space: pre-wrap;\">British Surrender to Nazis Dotes\n",
       "\n",
       "Back to Three Post-War Decisions: Hitler Saw They Would Not Fight After They Let Italy Take Ethiopia;\n",
       "\n",
       "After France Let Them Take Rhineland; And When Franco Was Not Checked\n",
       "\n",
       "WASHINGTON, September 9. - Here are two thumbnail sketches of history which should be kept in view.</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# Create HTML table with better formatting for comparison\n",
    "html_comparison = f\"\"\"\n",
    "<h2>Original vs Corrected Text</h2>\n",
    "<table style=\"width:100%; border-collapse: collapse;\">\n",
    "    <tr>\n",
    "        <th style=\"border: 1px solid black; padding: 8px; text-align: left; background-color: #f2f2f2;\">Original Text</th>\n",
    "        <th style=\"border: 1px solid black; padding: 8px; text-align: left; background-color: #f2f2f2;\">Corrected Text</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"border: 1px solid black; padding: 8px; vertical-align: top; white-space: pre-wrap;\">{dataset[2]['article']}</td>\n",
    "        <td style=\"border: 1px solid black; padding: 8px; vertical-align: top; white-space: pre-wrap;\">{corrected_text}</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(html_comparison))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always a good idea to do manual validation against the original source image. To find that we can check out the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article_id': '42_1938-09-23_p8_sn82014085_00393347417_1938092301_0313',\n",
       " 'newspaper_name': 'The Waterbury Democrat.',\n",
       " 'edition': '01',\n",
       " 'date': '1938-09-23',\n",
       " 'page': 'p8',\n",
       " 'headline': 'Daily fA\\n\\n Washington',\n",
       " 'byline': 'Ana ROnERT q ALLElg\\n\\nRy DREW PEARSON',\n",
       " 'article': 'British. Surrender to Nozs Dotes\\n\\n Back to Three Post-ANor Decisions; Hitler Saw They Would Not Fight After They Let Itoly. Toke Ethiopio;\\n\\n After France Let Them Toke Rhnelond;; M w And When Franco Was Not Checked\\n\\n WASHINGTON, September g. - Here are two. tl1vb-naN sketches of history which should be kept in Av1'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, it's in from `The Waterbury Democrat`, edition 01, page 8. If we go to the link below, we can see the image and here is the relevant section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the full article [here](https://www.loc.gov/resource/sn82014085/1938-09-23/ed-1/?sp=8&r=0.624,0.033,0.482,0.354,0)![article image](../assets/images/article.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "British Surrender to Nazis Dotes\n",
      "\n",
      "Back to Three Post-War Decisions: Hitler Saw They Would Not Fight After They Let Italy Take Ethiopia;\n",
      "\n",
      "After France Let Them Take Rhineland; And When Franco Was Not Checked\n",
      "\n",
      "WASHINGTON, September 9. - Here are two thumbnail sketches of history which should be kept in view.\n"
     ]
    }
   ],
   "source": [
    "print(corrected_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, we were lucky, our corrected OCR fairly closely mirrors the original image, despite having never seen it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Corrected OCR Output\n",
    "\n",
    "Now that we have used one LLM to correct the OCR, let's use another to solve our same NER problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"locations\":[{\"text\":\"Ethiopia\"},{\"text\":\"Rhineland\"},{\"text\":\"Washington\"}],\"people\":[{\"text\":\"Hitler\"},{\"text\":\"Franco\"}],\"nationalities\":[{\"text\":\"British\"},{\"text\":\"Nazis\"},{\"text\":\"French\"}]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "corrected_ocr_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant that identifies entities in a text.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Find entities in this text: {corrected_text}\"\n",
    "    }\n",
    "]\n",
    "\n",
    "class Location(BaseModel):\n",
    "    text: str\n",
    "\n",
    "class Person(BaseModel):\n",
    "    text: str\n",
    "\n",
    "class Nationality(BaseModel):\n",
    "    text: str\n",
    "\n",
    "\n",
    "class Entities(BaseModel):\n",
    "    locations: list[Location]\n",
    "    people: list[Person]\n",
    "    nationalities: list[Nationality]\n",
    "\n",
    "    \n",
    "response = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=corrected_ocr_messages,\n",
    "    response_format=Entities\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While your results will be a bit inconsistent, they should be slightly better. One error I continue to see is \"Nazi\" being applied to nationality. In some contexts, I can understand this, but we may want to have them be classified as \"Organization\" or maybe even \"Political Party\". You can always improve upon these classes as you see fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing Relationships between Entities\n",
    "\n",
    "Extracting entities is useful, but a far more challenging task is understand *how* those entities relate to one another. Traditionally humans could manually go through a text and construct a knowledge graph through triples. Triples are a set of three things: subject, relationship, and object. These can be sole-directional: Mary (Subject) is the mother (Relationship) of Susan (Object) or bi-directional. Mary (Subject) is related to (Relationship) Susan (Object) (and the opposite can be true.)\n",
    "\n",
    "When we understand the relationship between entities in our text, we can have a much better understanding of how those entities are functioning within the text. Doing this without LLMs can be very challenging and require a lot of domain expertise. LLMs make this prolbem a little easier. To see this, let's first grab our entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use these entities to extract a knowledge graph of triples from our text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"triples\":[{\"subject\":{\"text\":\"Italy\"},\"relationship\":{\"relationship\":\"took\"},\"object\":{\"text\":\"Ethiopia\"}},{\"subject\":{\"text\":\"France\"},\"relationship\":{\"relationship\":\"let take\"},\"object\":{\"text\":\"Rhineland\"}},{\"subject\":{\"text\":\"Franco\"},\"relationship\":{\"relationship\":\"was not checked\"},\"object\":{\"text\":\"\"}}]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tripples_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant that draws relationships between entities in a text.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Draw relationships between entities in this text: {corrected_text}. Here are the entities: {entities}\"\n",
    "    }\n",
    "]\n",
    "\n",
    "class Entity(BaseModel):\n",
    "    text: str\n",
    "\n",
    "class Relationship(BaseModel):\n",
    "    relationship: str\n",
    "\n",
    "\n",
    "class Triple(BaseModel):\n",
    "    subject: Entity\n",
    "    relationship: Relationship\n",
    "    object: Entity\n",
    "\n",
    "class Triples(BaseModel):\n",
    "    triples: list[Triple]\n",
    "    \n",
    "response = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=tripples_messages,\n",
    "    response_format=Triples\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make it a little easier to read this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject=Entity(text='Italy') relationship=Relationship(relationship='took') object=Entity(text='Ethiopia')\n",
      "\n",
      "subject=Entity(text='France') relationship=Relationship(relationship='let them take') object=Entity(text='Rhineland')\n",
      "\n",
      "subject=Entity(text='Franco') relationship=Relationship(relationship='was not checked') object=Entity(text='')\n",
      "\n",
      "subject=Entity(text='Hitler') relationship=Relationship(relationship='saw they would not fight after') object=Entity(text='Italy took Ethiopia')\n",
      "\n",
      "subject=Entity(text='Hitler') relationship=Relationship(relationship='saw they would not fight after') object=Entity(text='France let them take Rhineland')\n",
      "\n",
      "subject=Entity(text='Hitler') relationship=Relationship(relationship='saw they would not fight after') object=Entity(text='Franco was not checked')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for triple in response.choices[0].message.parsed.triples:\n",
    "    print(triple)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Complex Entities and their Metadata\n",
    "\n",
    "LLMs also allow us to solve other complex types of tasks that leverage NER. Imagine we needed to identify the women mentioned in the following text. What are some of the challenges you can foresee in this problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MANY prominent persons in Wash\n",
      "@ ington have consented to act as\n",
      "patronesses for the benefit perform\n",
      "ances of \"Once Is Enough\" Tuesday\n",
      "evening. sponsored by the Washington\n",
      "Bryn MaNr Club. The proceeds will\n",
      "60 to scholarship to the college for\n",
      "Washington student and the Bry1\n",
      "Mavr summer school for women work\n",
      "ers in industry.\n",
      "\n",
      "\n",
      "Nine. Troyanovsky, wife of the\n",
      "Soviet Ambassador, has taken a box\n",
      "and others who will entertain box\n",
      "parties include Mrs. Carroll Miller, DR..\n",
      "Ethel Dunham. Mrs. Jacob Simpson\n",
      "Payton, Mrs. Edward B. Meigs, Mrs\n",
      "Howell Moorhead and Mrs. Thomas\n",
      "McAllister.\n",
      "\n",
      "\n",
      "The patroness list. headed by Mrs.\n",
      "Franklin Delano Roosevelt, includes\n",
      "Mrs. Cordell Hull. Lady Lindsay,\n",
      "Madame Troyanovsky, Sonora de los\n",
      "Rios, Frau Dieckhoff, Madame Peter\n",
      "and Madame Pelonyi Also wives of\n",
      "associate justices of the Supreme\n",
      "Court. Mrs. Louis D. Brandeis, Mrs.\n",
      "Pierce Butler, Mrs. Harlan Fiske Stone\n",
      "and Mrs. Hugo Black.\n",
      "\n",
      "\n",
      "Mrs. Henry Morgenthau, jr., wife\n",
      "OF the Secretary of the Treasury; the\n",
      "Secretary of Labor Miss Frances Per-\n",
      "kins are included among the patron\n",
      "esses also. Mrs. John V. A. MacMur-\n",
      "ray. Mrs. Francis Sayre, Mrs. Wayne\n",
      "Chatfleld-Taylor, Mrs. William E..\n",
      "Borah, Mrs. Robert Woods Bliss, Mrs.\n",
      "William S. Culbertson, Miss Hilda\n",
      "Worthing Smith, Mrs. Thomas F. Nc\n",
      "Allister, Baroness Serge Korff, Mrs.\n",
      "Cary Grayson, Mrs. Edward B. Meigs,\n",
      "Mrs. L. Corrin Strong, Mrs. Eugene\n",
      "Meyer, Mrs. Albert Gushing Read, Mrs.\n",
      "Anson Phelps Stokes, Mrs. Luke Will\n",
      "son. DR.. Ethel Dunham, Mrs. Howell\n",
      "Moorhead. Mrs. Levi Cooke and Mrs.\n",
      "Frederic L. Chaplin.\n"
     ]
    }
   ],
   "source": [
    "print(dataset[500][\"article\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 2** (10 minutes)\n",
    "\n",
    "Read the text and think through a solution to the following problem. Find and identify the women referenced in this text, while separating them from their spouses. You don't need to write code here. Come up with a conceptional way to approach the problem given what you have already learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "woman_name=Woman(text='Nine Troyanovsky') spouse=Spouse(text='Troyanovsky')\n",
      "woman_name=Woman(text='Mrs. Carroll Miller') spouse=None\n",
      "woman_name=Woman(text='Ethel Dunham') spouse=None\n",
      "woman_name=Woman(text='Mrs. Jacob Simpson Payton') spouse=Spouse(text='Jacob Simpson Payton')\n",
      "woman_name=Woman(text='Mrs. Edward B. Meigs') spouse=Spouse(text='Edward B. Meigs')\n",
      "woman_name=Woman(text='Mrs. Howell Moorhead') spouse=Spouse(text='Howell Moorhead')\n",
      "woman_name=Woman(text='Mrs. Thomas McAllister') spouse=Spouse(text='Thomas McAllister')\n",
      "woman_name=Woman(text='Mrs. Franklin Delano Roosevelt') spouse=Spouse(text='Franklin Delano Roosevelt')\n",
      "woman_name=Woman(text='Mrs. Cordell Hull') spouse=Spouse(text='Cordell Hull')\n",
      "woman_name=Woman(text='Lady Lindsay') spouse=None\n",
      "woman_name=Woman(text='Madame Troyanovsky') spouse=Spouse(text='Troyanovsky')\n",
      "woman_name=Woman(text='Sonora de los Rios') spouse=None\n",
      "woman_name=Woman(text='Frau Dieckhoff') spouse=None\n",
      "woman_name=Woman(text='Madame Peter') spouse=None\n",
      "woman_name=Woman(text='Madame Pelonyi') spouse=None\n",
      "woman_name=Woman(text='Mrs. Louis D. Brandeis') spouse=Spouse(text='Louis D. Brandeis')\n",
      "woman_name=Woman(text='Mrs. Pierce Butler') spouse=Spouse(text='Pierce Butler')\n",
      "woman_name=Woman(text='Mrs. Harlan Fiske Stone') spouse=Spouse(text='Harlan Fiske Stone')\n",
      "woman_name=Woman(text='Mrs. Hugo Black') spouse=Spouse(text='Hugo Black')\n",
      "woman_name=Woman(text='Mrs. Henry Morgenthau, jr.') spouse=Spouse(text='Henry Morgenthau, jr.')\n",
      "woman_name=Woman(text='Frances Perkins') spouse=None\n",
      "woman_name=Woman(text='Mrs. John V. A. MacMurray') spouse=Spouse(text='John V. A. MacMurray')\n",
      "woman_name=Woman(text='Mrs. Francis Sayre') spouse=Spouse(text='Francis Sayre')\n",
      "woman_name=Woman(text='Mrs. Wayne Chatfleld-Taylor') spouse=Spouse(text='Wayne Chatfleld-Taylor')\n",
      "woman_name=Woman(text='Mrs. William E. Borah') spouse=Spouse(text='William E. Borah')\n",
      "woman_name=Woman(text='Mrs. Robert Woods Bliss') spouse=Spouse(text='Robert Woods Bliss')\n",
      "woman_name=Woman(text='Mrs. William S. Culbertson') spouse=Spouse(text='William S. Culbertson')\n",
      "woman_name=Woman(text='Hilda Worthing Smith') spouse=None\n",
      "woman_name=Woman(text='Mrs. Thomas F. McAllister') spouse=Spouse(text='Thomas F. McAllister')\n",
      "woman_name=Woman(text='Baroness Serge Korff') spouse=None\n",
      "woman_name=Woman(text='Mrs. Cary Grayson') spouse=Spouse(text='Cary Grayson')\n",
      "woman_name=Woman(text='Mrs. L. Corrin Strong') spouse=Spouse(text='L. Corrin Strong')\n",
      "woman_name=Woman(text='Mrs. Eugene Meyer') spouse=Spouse(text='Eugene Meyer')\n",
      "woman_name=Woman(text='Mrs. Albert Cushing Read') spouse=Spouse(text='Albert Cushing Read')\n",
      "woman_name=Woman(text='Mrs. Anson Phelps Stokes') spouse=Spouse(text='Anson Phelps Stokes')\n",
      "woman_name=Woman(text='Mrs. Luke Willson') spouse=Spouse(text='Luke Willson')\n",
      "woman_name=Woman(text='Ethel Dunham') spouse=None\n",
      "woman_name=Woman(text='Mrs. Howell Moorhead') spouse=Spouse(text='Howell Moorhead')\n",
      "woman_name=Woman(text='Mrs. Levi Cooke') spouse=Spouse(text='Levi Cooke')\n",
      "woman_name=Woman(text='Mrs. Frederic L. Chaplin') spouse=Spouse(text='Frederic L. Chaplin')\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "ner_women = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant that identifies women in a text. Only return the names of women who are clearly identified by either pronoun or honorifics. If her name is attached to her spouse, separate her spouse's name from hers. This is true for examples like 'Mrs. John Smith' or 'John Smith and his wife, Mrs. John Smith'.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Identify women in this text: {dataset[500]['article']}\"\n",
    "    }\n",
    "]\n",
    "\n",
    "class Woman(BaseModel):\n",
    "    text: str\n",
    "\n",
    "class Spouse(BaseModel):\n",
    "    text: str\n",
    "\n",
    "class Woman(BaseModel):\n",
    "    woman_name: Woman\n",
    "    spouse: Optional[Spouse]\n",
    "\n",
    "class Women(BaseModel):\n",
    "    women: list[Woman]\n",
    "\n",
    "    \n",
    "response = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=ner_women,\n",
    "    response_format=Women\n",
    ")\n",
    "\n",
    "for woman in response.choices[0].message.parsed.women:\n",
    "    print(woman)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the New Models from OpenAI\n",
    "\n",
    "While this notebook was created and used (April 2025) several new OpenAI models were released. I encourage you to use one of the newer models and test out the workflows listed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-audio-preview-2024-12-17\n",
      "dall-e-3\n",
      "text-embedding-3-large\n",
      "dall-e-2\n",
      "o4-mini-2025-04-16\n",
      "gpt-4o-audio-preview-2024-10-01\n",
      "o4-mini\n",
      "gpt-4.1-nano\n",
      "gpt-4.1-nano-2025-04-14\n",
      "gpt-4o-realtime-preview-2024-10-01\n",
      "gpt-4o-realtime-preview\n",
      "babbage-002\n",
      "tts-1-hd-1106\n",
      "gpt-4\n",
      "text-embedding-ada-002\n",
      "o1-2024-12-17\n",
      "o1-pro-2025-03-19\n",
      "o1\n",
      "tts-1-hd\n",
      "gpt-4o-mini-audio-preview\n",
      "o1-pro\n",
      "gpt-4o-audio-preview\n",
      "o1-preview-2024-09-12\n",
      "gpt-4o-mini-realtime-preview\n",
      "gpt-4.1-mini\n",
      "gpt-4o-mini-realtime-preview-2024-12-17\n",
      "gpt-3.5-turbo-instruct-0914\n",
      "gpt-4o-mini-search-preview\n",
      "gpt-4.1-mini-2025-04-14\n",
      "tts-1-1106\n",
      "chatgpt-4o-latest\n",
      "davinci-002\n",
      "gpt-3.5-turbo-1106\n",
      "gpt-4o-search-preview\n",
      "gpt-4-turbo\n",
      "gpt-4o-realtime-preview-2024-12-17\n",
      "gpt-3.5-turbo-instruct\n",
      "gpt-3.5-turbo\n",
      "gpt-4-turbo-preview\n",
      "gpt-4o-mini-search-preview-2025-03-11\n",
      "gpt-4-0125-preview\n",
      "gpt-4o-2024-11-20\n",
      "whisper-1\n",
      "gpt-4o-2024-05-13\n",
      "gpt-4-turbo-2024-04-09\n",
      "gpt-3.5-turbo-16k\n",
      "o1-preview\n",
      "gpt-4-0613\n",
      "gpt-4.5-preview\n",
      "gpt-4.5-preview-2025-02-27\n",
      "gpt-4o-search-preview-2025-03-11\n",
      "o3-mini\n",
      "o3-mini-2025-01-31\n",
      "tts-1\n",
      "omni-moderation-2024-09-26\n",
      "text-embedding-3-small\n",
      "gpt-4o-mini-tts\n",
      "gpt-4o\n",
      "gpt-4o-mini\n",
      "gpt-4o-2024-08-06\n",
      "gpt-4.1\n",
      "gpt-4o-transcribe\n",
      "gpt-4.1-2025-04-14\n",
      "gpt-4o-mini-2024-07-18\n",
      "gpt-4o-mini-transcribe\n",
      "o1-mini\n",
      "gpt-4o-mini-audio-preview-2024-12-17\n",
      "gpt-3.5-turbo-0125\n",
      "o1-mini-2024-09-12\n",
      "gpt-4-1106-preview\n",
      "omni-moderation-latest\n",
      "ada:ft-personal:vulgate-2023-04-18-17-48-10\n",
      "ada:ft-personal:vulgate-2023-04-18-16-45-55\n"
     ]
    }
   ],
   "source": [
    "for model in client.models.list():\n",
    "    print(model.id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
